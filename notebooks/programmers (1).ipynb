{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Defining Compute\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_name = \"aiml-cpu\""
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762160120
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Importing Packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762165249
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Defining Versions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version_string = '1'"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762341013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rai_programmer_example_version_string = '5'"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762343418
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Defining paths to the data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = 'data-programmer-regression/train/'"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762167202
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = 'data-programmer-regression/test/'"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762170610
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Defining Target Column"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_column_name = \"score\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762173548
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Creating an MLClient for interactions with AzureML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please make sure you have uploaded config.json file in the parent directory\r\n",
        "from azure.ai.ml import MLClient\r\n",
        "from azure.identity import DefaultAzureCredential\r\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential(exclude_shared_token_cache_credential=True),\r\n",
        "                     logging_enable=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/aiml-cpu/code/Users/2088948/Rai-dashboard/config.json\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762180582
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Uploading Data to Azure Ml"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "input_train_data = \"Programmers_Train_MLTable\"\r\n",
        "input_test_data = \"Programmers_Test_MLTable\"\r\n",
        "\r\n",
        "train_data = Data(\r\n",
        "    path=train_data_path,\r\n",
        "    type=AssetTypes.MLTABLE,\r\n",
        "    description=\"RAI programmers training data\",\r\n",
        "    name=input_train_data,\r\n",
        "    version=rai_programmer_example_version_string,\r\n",
        ")\r\n",
        "ml_client.data.create_or_update(train_data)\r\n",
        "\r\n",
        "test_data = Data(\r\n",
        "    path=test_data_path,\r\n",
        "    type=AssetTypes.MLTABLE,\r\n",
        "    description=\"RAI programmers test data\",\r\n",
        "    name=input_test_data,\r\n",
        "    version=rai_programmer_example_version_string,\r\n",
        ")\r\n",
        "ml_client.data.create_or_update(test_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading train (0.02 MBs): 100%|██████████| 19511/19511 [00:00<00:00, 444941.99it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "error",
          "ename": "HttpResponseError",
          "evalue": "(UserError) A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's data uri cannot be changed. Only tags, description, and isArchived can be updated.\nCode: UserError\nMessage: A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's data uri cannot be changed. Only tags, description, and isArchived can be updated.\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"c9181688a5b4ca488e64d535b1a3c0ed\",\n        \"request\": \"8d70664c0e344dd4\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"eastus\"\n}Type: Location\nInfo: {\n    \"value\": \"eastus\"\n}Type: Time\nInfo: {\n    \"value\": \"2022-10-26T05:33:42.2283809+00:00\"\n}Type: InnerError\nInfo: {\n    \"value\": {\n        \"code\": \"Immutable\",\n        \"innerError\": {\n            \"code\": \"DataVersionPropertyImmutable\",\n            \"innerError\": null\n        }\n    }\n}Type: MessageFormat\nInfo: {\n    \"value\": \"A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's {property} cannot be changed. Only tags, description, and isArchived can be updated.\"\n}Type: MessageParameters\nInfo: {\n    \"value\": {\n        \"property\": \"data uri\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m input_test_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgrammers_Test_MLTable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m train_data \u001b[38;5;241m=\u001b[39m Data(\n\u001b[1;32m      8\u001b[0m     path\u001b[38;5;241m=\u001b[39mtrain_data_path,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mAssetTypes\u001b[38;5;241m.\u001b[39mMLTABLE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     version\u001b[38;5;241m=\u001b[39mrai_programmer_example_version_string,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m test_data \u001b[38;5;241m=\u001b[39m Data(\n\u001b[1;32m     17\u001b[0m     path\u001b[38;5;241m=\u001b[39mtest_data_path,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mAssetTypes\u001b[38;5;241m.\u001b[39mMLTABLE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     version\u001b[38;5;241m=\u001b[39mrai_programmer_example_version_string,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m ml_client\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcreate_or_update(test_data)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/_telemetry/activity.py:260\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[0;32m--> 260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/operations/_data_operations.py:206\u001b[0m, in \u001b[0;36mDataOperations.create_or_update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ex) \u001b[38;5;241m==\u001b[39m ASSET_PATH_ERROR:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AssetPathException(\n\u001b[1;32m    201\u001b[0m             message\u001b[38;5;241m=\u001b[39mCHANGED_ASSET_PATH_MSG,\n\u001b[1;32m    202\u001b[0m             tartget\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mDATA,\n\u001b[1;32m    203\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39mCHANGED_ASSET_PATH_MSG_NO_PERSONAL_DATA,\n\u001b[1;32m    204\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    205\u001b[0m         )\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/operations/_data_operations.py:185\u001b[0m, in \u001b[0;36mDataOperations.create_or_update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    175\u001b[0m         result \u001b[38;5;241m=\u001b[39m _create_or_update_autoincrement(\n\u001b[1;32m    176\u001b[0m             name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    177\u001b[0m             body\u001b[38;5;241m=\u001b[39mdata_version_resource,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_kwargs,\n\u001b[1;32m    183\u001b[0m         )\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_version_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scope_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Data\u001b[38;5;241m.\u001b[39m_from_rest_object(result)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/_restclient/v2022_05_01/operations/_data_versions_operations.py:528\u001b[0m, in \u001b[0;36mDataVersionsOperations.create_or_update\u001b[0;34m(self, resource_group_name, workspace_name, name, version, body, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[1;32m    527\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror, error_format\u001b[38;5;241m=\u001b[39mARMErrorFormat)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    531\u001b[0m     deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataVersionBaseData\u001b[39m\u001b[38;5;124m'\u001b[39m, pipeline_response)\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (UserError) A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's data uri cannot be changed. Only tags, description, and isArchived can be updated.\nCode: UserError\nMessage: A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's data uri cannot be changed. Only tags, description, and isArchived can be updated.\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"c9181688a5b4ca488e64d535b1a3c0ed\",\n        \"request\": \"8d70664c0e344dd4\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"eastus\"\n}Type: Location\nInfo: {\n    \"value\": \"eastus\"\n}Type: Time\nInfo: {\n    \"value\": \"2022-10-26T05:33:42.2283809+00:00\"\n}Type: InnerError\nInfo: {\n    \"value\": {\n        \"code\": \"Immutable\",\n        \"innerError\": {\n            \"code\": \"DataVersionPropertyImmutable\",\n            \"innerError\": null\n        }\n    }\n}Type: MessageFormat\nInfo: {\n    \"value\": \"A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's {property} cannot be changed. Only tags, description, and isArchived can be updated.\"\n}Type: MessageParameters\nInfo: {\n    \"value\": {\n        \"property\": \"data uri\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762422335
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Creating a directory for the Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "os.mkdir('programmer_component_src')"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762190104
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Training script to create the model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile programmer_component_src/training_script_reg.py\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import mltable\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\r\n",
        "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\r\n",
        "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "def create_regression_pipeline(X, y):\r\n",
        "    pipe_cfg = {\r\n",
        "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\r\n",
        "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\r\n",
        "    }\r\n",
        "    num_pipe = Pipeline([\r\n",
        "        ('num_imputer', SimpleImputer(strategy='median')),\r\n",
        "        ('num_scaler', StandardScaler())\r\n",
        "    ])\r\n",
        "    cat_pipe = Pipeline([\r\n",
        "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\r\n",
        "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\r\n",
        "    ])\r\n",
        "    feat_pipe = ColumnTransformer([\r\n",
        "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\r\n",
        "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\r\n",
        "    ])\r\n",
        "\r\n",
        "    # Append classifier to preprocessing pipeline.\r\n",
        "    # Now we have a full prediction pipeline.\r\n",
        "    pipeline = Pipeline(steps=[('preprocessor', feat_pipe),\r\n",
        "                               ('model', LinearRegression())])\r\n",
        "    return pipeline.fit(X, y)\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "    \r\n",
        "    # Read in data\r\n",
        "    print(\"Reading data\")\r\n",
        "    tbl = mltable.load(args.training_data)\r\n",
        "    all_data = tbl.to_pandas_dataframe()\r\n",
        "\r\n",
        "    print(\"Extracting X_train, y_train\")\r\n",
        "    print(\"all_data cols: {0}\".format(all_data.columns))\r\n",
        "    y_train = all_data[args.target_column_name]\r\n",
        "    X_train = all_data.drop(labels=args.target_column_name, axis=\"columns\")\r\n",
        "    print(\"X_train cols: {0}\".format(X_train.columns))\r\n",
        "\r\n",
        "    print(\"Training model\")\r\n",
        "    # The estimator can be changed to suit\r\n",
        "    model = create_regression_pipeline(X_train, y_train)\r\n",
        "\r\n",
        "    # Saving model with mlflow - leave this section unchanged\r\n",
        "    with tempfile.TemporaryDirectory() as td:\r\n",
        "        print(\"Saving model with MLFlow to temporary directory\")\r\n",
        "        tmp_output_dir = os.path.join(td, \"my_model_dir\")\r\n",
        "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\r\n",
        "\r\n",
        "        print(\"Copying MLFlow model to output path\")\r\n",
        "        for file_name in os.listdir(tmp_output_dir):\r\n",
        "            print(\"  Copying: \", file_name)\r\n",
        "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\r\n",
        "            # an option, removing the need for listdir\r\n",
        "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing programmer_component_src/training_script_reg.py\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Building the training script into the component"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\r\n",
        "\r\n",
        "yaml_contents = f\"\"\"\r\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\r\n",
        "name: rai_programmers_training_component\r\n",
        "display_name: Programmers training component for RAI example\r\n",
        "version: {rai_programmer_example_version_string}\r\n",
        "type: command\r\n",
        "inputs:\r\n",
        "  training_data:\r\n",
        "    type: path\r\n",
        "  target_column_name:\r\n",
        "    type: string\r\n",
        "outputs:\r\n",
        "  model_output:\r\n",
        "    type: path\r\n",
        "code: ./programmer_component_src/\r\n",
        "environment: azureml:AML-RAI-Environment:{version_string}\r\n",
        "command: >-\r\n",
        "  python training_script_reg.py\r\n",
        "  --training_data ${{{{inputs.training_data}}}}\r\n",
        "  --target_column_name ${{{{inputs.target_column_name}}}}\r\n",
        "  --model_output ${{{{outputs.model_output}}}}\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "yaml_filename = \"ProgrammersRegTrainingComp.yaml\"\r\n",
        "\r\n",
        "with open(yaml_filename, 'w') as f:\r\n",
        "    f.write(yaml_contents)\r\n",
        "    \r\n",
        "train_component_definition = load_component(\r\n",
        "    path=yaml_filename\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.components.create_or_update(train_component_definition)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "CommandComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'name': 'rai_programmers_training_component', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/dac80204-eb42-40d9-bbce-ab95219bd21b/resourceGroups/rg-poc-aiml-price-east/providers/Microsoft.MachineLearningServices/workspaces/mlw-poc-aiml-price-east/components/rai_programmers_training_component/versions/5', 'Resource__source_path': None, 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f1b9cfc7490>, 'serialize': <msrest.serialization.Serializer object at 0x7f1b9cf1e700>, 'command': 'python training_script_reg.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/dac80204-eb42-40d9-bbce-ab95219bd21b/resourceGroups/rg-poc-aiml-price-east/providers/Microsoft.MachineLearningServices/workspaces/mlw-poc-aiml-price-east/codes/c9e9391b-f023-4443-8ca9-95337d8f31a2/versions/1', 'environment_variables': None, 'environment': '/subscriptions/dac80204-eb42-40d9-bbce-ab95219bd21b/resourceGroups/rg-poc-aiml-price-east/providers/Microsoft.MachineLearningServices/workspaces/mlw-poc-aiml-price-east/environments/AML-RAI-Environment/versions/1', 'distribution': None, 'resources': {'instance_count': 1, 'properties': {}}, 'version': '5', 'latest_version': None, 'schema': 'http://azureml/sdk-2-0/CommandComponent.json', 'type': 'command', 'display_name': 'Programmers training component for RAI example', 'is_deterministic': True, 'inputs': {'training_data': {'type': 'path'}, 'target_column_name': {'type': 'string'}}, 'outputs': {'model_output': {'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] Programmers training component for RAI example at 0x7f1b9d050700>})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762356018
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Defining the Model Name "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "\r\n",
        "model_name_suffix = int(time.time())\r\n",
        "model_name = 'rai_programmer_example_reg2'"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762366291
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Defining the training Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input\r\n",
        "\r\n",
        "register_component = ml_client.components.get(\r\n",
        "    name=\"register_model\", version=version_string\r\n",
        ")\r\n",
        "train_model_component = ml_client.components.get(\r\n",
        "    name=\"rai_programmers_training_component\", version=rai_programmer_example_version_string\r\n",
        ")\r\n",
        "programmers_train_mltable = Input(\r\n",
        "    type=\"mltable\", path=f\"{input_train_data}:{rai_programmer_example_version_string}\", mode=\"download\"\r\n",
        ")\r\n",
        "programmers_test_mltable = Input(\r\n",
        "    type=\"mltable\", path=f\"{input_test_data}:{rai_programmer_example_version_string}\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "    compute=compute_name,\r\n",
        "    description=\"Register Model for RAI Programmers example\",\r\n",
        "    experiment_name=f\"RAI_Programmers_Example_Model_Training_{model_name_suffix}\",\r\n",
        ")\r\n",
        "def my_training_pipeline(target_column_name, training_data):\r\n",
        "    trained_model = train_component_definition(\r\n",
        "        target_column_name=target_column_name,\r\n",
        "        training_data=training_data\r\n",
        "    )\r\n",
        "    trained_model.set_limits(timeout=120)\r\n",
        "\r\n",
        "    _ = register_component(\r\n",
        "        model_input_path=trained_model.outputs.model_output,\r\n",
        "        model_base_name=model_name,\r\n",
        "        model_name_suffix=model_name_suffix,\r\n",
        "    )\r\n",
        "\r\n",
        "    return {}\r\n",
        "\r\n",
        "model_registration_pipeline_job = my_training_pipeline(target_column_name, programmers_train_mltable)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762441009
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Submit the training Pipeline for Exceution"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\r\n",
        "\r\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\r\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\r\n",
        "    assert created_job is not None\r\n",
        "\r\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\r\n",
        "        time.sleep(30)\r\n",
        "        created_job = ml_client.jobs.get(created_job.name)\r\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\r\n",
        "    assert created_job.status == 'Completed'\r\n",
        "    return created_job\r\n",
        "\r\n",
        "# This is the actual submission\r\n",
        "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Completed\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666762605662
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}