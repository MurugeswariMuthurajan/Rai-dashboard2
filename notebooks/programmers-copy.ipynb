{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Defining Compute\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your compute instance's name\r\n",
        "compute_name = \"aiml-cpu\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Importing Packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Defining paths to the data and target column"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = 'data-programmer-regression/train/'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = 'data-programmer-regression/test/'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_column_name = \"score\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Defining Versions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version_string = '1'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rai_programmer_example_version_string = '5'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Creating an MLClient for interactions with AzureML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please make sure you have uploaded config.json file in the parent directory\r\n",
        "from azure.ai.ml import MLClient\r\n",
        "from azure.identity import DefaultAzureCredential\r\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential(exclude_shared_token_cache_credential=True),\r\n",
        "                     logging_enable=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Uploading Data to Azure Ml"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "input_train_data = \"Programmers_Train_MLTable\"\r\n",
        "input_test_data = \"Programmers_Test_MLTable\"\r\n",
        "\r\n",
        "train_data = Data(\r\n",
        "    path=train_data_path,\r\n",
        "    type=AssetTypes.MLTABLE,\r\n",
        "    description=\"RAI programmers training data\",\r\n",
        "    name=input_train_data,\r\n",
        "    version=rai_programmer_example_version_string,\r\n",
        ")\r\n",
        "ml_client.data.create_or_update(train_data)\r\n",
        "\r\n",
        "test_data = Data(\r\n",
        "    path=test_data_path,\r\n",
        "    type=AssetTypes.MLTABLE,\r\n",
        "    description=\"RAI programmers test data\",\r\n",
        "    name=input_test_data,\r\n",
        "    version=rai_programmer_example_version_string,\r\n",
        ")\r\n",
        "ml_client.data.create_or_update(test_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Creating a directory for the Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "os.mkdir('programmer_component_src')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Training script to create the model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile programmer_component_src/training_script_reg.py\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import mltable\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\r\n",
        "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\r\n",
        "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "def create_regression_pipeline(X, y):\r\n",
        "    pipe_cfg = {\r\n",
        "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\r\n",
        "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\r\n",
        "    }\r\n",
        "    num_pipe = Pipeline([\r\n",
        "        ('num_imputer', SimpleImputer(strategy='median')),\r\n",
        "        ('num_scaler', StandardScaler())\r\n",
        "    ])\r\n",
        "    cat_pipe = Pipeline([\r\n",
        "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\r\n",
        "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\r\n",
        "    ])\r\n",
        "    feat_pipe = ColumnTransformer([\r\n",
        "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\r\n",
        "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\r\n",
        "    ])\r\n",
        "\r\n",
        "    # Append classifier to preprocessing pipeline.\r\n",
        "    # Now we have a full prediction pipeline.\r\n",
        "    pipeline = Pipeline(steps=[('preprocessor', feat_pipe),\r\n",
        "                               ('model', LinearRegression())])\r\n",
        "    return pipeline.fit(X, y)\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "    \r\n",
        "    # Read in data\r\n",
        "    print(\"Reading data\")\r\n",
        "    tbl = mltable.load(args.training_data)\r\n",
        "    all_data = tbl.to_pandas_dataframe()\r\n",
        "\r\n",
        "    print(\"Extracting X_train, y_train\")\r\n",
        "    print(\"all_data cols: {0}\".format(all_data.columns))\r\n",
        "    y_train = all_data[args.target_column_name]\r\n",
        "    X_train = all_data.drop(labels=args.target_column_name, axis=\"columns\")\r\n",
        "    print(\"X_train cols: {0}\".format(X_train.columns))\r\n",
        "\r\n",
        "    print(\"Training model\")\r\n",
        "    # The estimator can be changed to suit\r\n",
        "    model = create_regression_pipeline(X_train, y_train)\r\n",
        "\r\n",
        "    # Saving model with mlflow - leave this section unchanged\r\n",
        "    with tempfile.TemporaryDirectory() as td:\r\n",
        "        print(\"Saving model with MLFlow to temporary directory\")\r\n",
        "        tmp_output_dir = os.path.join(td, \"my_model_dir\")\r\n",
        "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\r\n",
        "\r\n",
        "        print(\"Copying MLFlow model to output path\")\r\n",
        "        for file_name in os.listdir(tmp_output_dir):\r\n",
        "            print(\"  Copying: \", file_name)\r\n",
        "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\r\n",
        "            # an option, removing the need for listdir\r\n",
        "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Building the training script into the component"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\r\n",
        "\r\n",
        "yaml_contents = f\"\"\"\r\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\r\n",
        "name: rai_programmers_training_component\r\n",
        "display_name: Programmers training component for RAI example\r\n",
        "version: {rai_programmer_example_version_string}\r\n",
        "type: command\r\n",
        "inputs:\r\n",
        "  training_data:\r\n",
        "    type: path\r\n",
        "  target_column_name:\r\n",
        "    type: string\r\n",
        "outputs:\r\n",
        "  model_output:\r\n",
        "    type: path\r\n",
        "code: ./programmer_component_src/\r\n",
        "environment: azureml:AML-RAI-Environment:{version_string}\r\n",
        "command: >-\r\n",
        "  python training_script_reg.py\r\n",
        "  --training_data ${{{{inputs.training_data}}}}\r\n",
        "  --target_column_name ${{{{inputs.target_column_name}}}}\r\n",
        "  --model_output ${{{{outputs.model_output}}}}\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "yaml_filename = \"ProgrammersRegTrainingComp.yaml\"\r\n",
        "\r\n",
        "with open(yaml_filename, 'w') as f:\r\n",
        "    f.write(yaml_contents)\r\n",
        "    \r\n",
        "train_component_definition = load_component(\r\n",
        "    path=yaml_filename\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.components.create_or_update(train_component_definition)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Defining Model Name and Training Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "\r\n",
        "model_name_suffix = int(time.time())\r\n",
        "model_name = 'rai_programmer_example_reg'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input\r\n",
        "\r\n",
        "register_component = ml_client.components.get(\r\n",
        "    name=\"register_model\", version=version_string\r\n",
        ")\r\n",
        "train_model_component = ml_client.components.get(\r\n",
        "    name=\"rai_programmers_training_component\", version=rai_programmer_example_version_string\r\n",
        ")\r\n",
        "programmers_train_mltable = Input(\r\n",
        "    type=\"mltable\", path=f\"{input_train_data}:{rai_programmer_example_version_string}\", mode=\"download\"\r\n",
        ")\r\n",
        "programmers_test_mltable = Input(\r\n",
        "    type=\"mltable\", path=f\"{input_test_data}:{rai_programmer_example_version_string}\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "    compute=compute_name,\r\n",
        "    description=\"Register Model for RAI Programmers example\",\r\n",
        "    experiment_name=f\"RAI_Programmers_Example_Model_Training_{model_name_suffix}\",\r\n",
        ")\r\n",
        "def my_training_pipeline(target_column_name, training_data):\r\n",
        "    trained_model = train_component_definition(\r\n",
        "        target_column_name=target_column_name,\r\n",
        "        training_data=training_data\r\n",
        "    )\r\n",
        "    trained_model.set_limits(timeout=120)\r\n",
        "\r\n",
        "    _ = register_component(\r\n",
        "        model_input_path=trained_model.outputs.model_output,\r\n",
        "        model_base_name=model_name,\r\n",
        "        model_name_suffix=model_name_suffix,\r\n",
        "    )\r\n",
        "\r\n",
        "    return {}\r\n",
        "\r\n",
        "model_registration_pipeline_job = my_training_pipeline(target_column_name, programmers_train_mltable)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Submit the training Pipeline for Exceution"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\r\n",
        "\r\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\r\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\r\n",
        "    assert created_job is not None\r\n",
        "\r\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\r\n",
        "        time.sleep(30)\r\n",
        "        created_job = ml_client.jobs.get(created_job.name)\r\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\r\n",
        "    assert created_job.status == 'Completed'\r\n",
        "    return created_job\r\n",
        "\r\n",
        "# This is the actual submission\r\n",
        "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}